from flask import Flask, render_template, request, jsonify, send_file
from flask_cors import CORS
import torch
import torch.nn.functional as F
import torchvision.models as models
import torchvision.transforms as transforms  
from transformers import AutoImageProcessor, AutoModelForImageClassification 
from PIL import Image, ImageOps
import numpy as np
from scipy.ndimage import gaussian_filter
import base64
import io
import os
import requests
import json

app = Flask(__name__)

# CORS ì„¤ì •
CORS(app, origins=[
    "http://localhost:3000",  # React
    "http://localhost:8080",  # Vue
    "http://localhost:5173",  # Vite
    "http://127.0.0.1:3000",
    "http://127.0.0.1:8080",
    "http://127.0.0.1:5173"
])

# ëª¨ë¸ ë¡œë“œ
print("ğŸ¨ WikiArt-Style ì˜ˆìˆ  ë¶„ë¥˜ ëª¨ë¸ ë¡œë”© ì¤‘...")
art_processor = AutoImageProcessor.from_pretrained("prithivMLmods/WikiArt-Style")
art_model = AutoModelForImageClassification.from_pretrained("prithivMLmods/WikiArt-Style")
print("âœ… WikiArt-Style ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! (137ê°œ ì˜ˆìˆ  ìŠ¤íƒ€ì¼ ì§€ì›)")

def get_art_classes():
    """ì˜ˆìˆ  ë¶„ë¥˜ í´ë˜ìŠ¤ ë°˜í™˜"""
    if art_model:
        return art_model.config.id2label
    return {}

art_classes = get_art_classes()

def classify_with_art_model(image_tensor):
    """WikiArt-Style ëª¨ë¸ë¡œ ì˜ˆìˆ  ë¶„ë¥˜"""
    try:
        if len(image_tensor.shape) == 4:
            image_tensor = image_tensor.squeeze(0)
        
        image_pil = transforms.ToPILImage()(image_tensor.clamp(0, 1))
        inputs = art_processor(images=image_pil, return_tensors="pt")
        
        with torch.no_grad():
            outputs = art_model(**inputs)
            predictions = F.softmax(outputs.logits, dim=-1)
            
        # âœ… ì´ ë¶€ë¶„ì„ ìˆ˜ì •
        predicted_idx = predictions.argmax()  # .item() ì œê±°
        confidence = predictions.max()        # .item() ì œê±°
        predicted_class = art_classes.get(predicted_idx.item(), "Unknown_Style")
        
        # âœ… ëª…ì‹œì ìœ¼ë¡œ float ë³€í™˜
        return predicted_class, float(confidence), int(predicted_idx)
    except Exception as e:
        print(f"âŒ ì˜ˆìˆ  ë¶„ë¥˜ ì‹¤íŒ¨: {e}")
        return "Post-Impressionism", 0.75, 0

def flexible_resize_transform(image, max_size=224):
    original_size = image.size
    
    if original_size[0] > original_size[1]:
        new_width = max_size
        new_height = int(max_size * original_size[1] / original_size[0])
    else:
        new_height = max_size
        new_width = int(max_size * original_size[0] / original_size[1])
    
    resized_image = image.resize((new_width, new_height), Image.BICUBIC)
    
    padding_left = (max_size - new_width) // 2
    padding_top = (max_size - new_height) // 2
    padding_right = max_size - new_width - padding_left
    padding_bottom = max_size - new_height - padding_top
    
    padded_image = ImageOps.expand(
        resized_image, 
        border=(padding_left, padding_top, padding_right, padding_bottom), 
        fill=0
    )
    
    img_np = np.array(padded_image).astype(np.float32) / 255.0
    img_np = img_np.transpose((2, 0, 1))
    
    return torch.from_numpy(img_np)

def fgsm_attack_with_blur(image_tensor, base_epsilon=0.015, base_sigma=0.4):
    image_tensor = image_tensor.clone().unsqueeze(0).requires_grad_(True)
    
    original_class, conf, original_pred = classify_with_art_model(image_tensor)
    
    # ì ì‘ì  ì—¡ì‹¤ë¡  ì¡°ì • 
    if conf > 0.99:
        eps = base_epsilon * 4.0
        sigma = base_sigma * 0.3
    elif conf > 0.95:
        eps = base_epsilon * 2.5
        sigma = base_sigma * 0.5
    elif conf > 0.9:
        eps = base_epsilon * 1.5
        sigma = base_sigma
    else:
        eps = base_epsilon
        sigma = base_sigma
    
    # âœ… ì˜ˆìˆ  ëª¨ë¸ë¡œ FGSM ê³µê²©
    try:
        # ì˜ˆìˆ  ëª¨ë¸ë¡œ gradient ê³„ì‚°
        image_pil = transforms.ToPILImage()(image_tensor.squeeze().clamp(0, 1))
        inputs = art_processor(images=image_pil, return_tensors="pt")
        inputs['pixel_values'].requires_grad_(True)
        
        outputs = art_model(**inputs)
        target = torch.tensor([original_pred])
        loss = F.cross_entropy(outputs.logits, target)
        
        # Gradient ê¸°ë°˜ perturbation
        loss.backward()
        
        if inputs['pixel_values'].grad is not None:
            perturbation = eps * inputs['pixel_values'].grad.sign()
            # í¬ê¸° ë§ì¶¤
            if perturbation.shape != image_tensor.shape:
                perturbation = F.interpolate(perturbation, size=image_tensor.shape[2:], mode='bilinear')
            adv_image = image_tensor + perturbation
            print(f"âœ… ì˜ˆìˆ  ëª¨ë¸ gradient ê¸°ë°˜ FGSM ì ìš©!")
        else:
            raise Exception("Gradient ê³„ì‚° ì‹¤íŒ¨")
            
    except Exception as e:
        print(f"âš ï¸ ì˜ˆìˆ  ëª¨ë¸ gradient ì‹¤íŒ¨, fallback ì‚¬ìš©: {e}")
        # ê¸°ì¡´ ë°©ì‹ìœ¼ë¡œ fallback
        perturbation = eps * torch.randn_like(image_tensor)
        adv_image = image_tensor + perturbation
    
    adv_image = torch.clamp(adv_image, 0, 1)
    
    # ê°€ìš°ì‹œì•ˆ ë¸”ëŸ¬
    adv_np = adv_image.squeeze(0).detach().cpu().numpy()
    adv_blur_np = np.stack([gaussian_filter(c, sigma=sigma) for c in adv_np])
    adv_blur = torch.from_numpy(adv_blur_np).unsqueeze(0)

    # âœ… ì ëŒ€ì  ì˜ˆìˆ  ë¶„ë¥˜
    adversarial_class, adversarial_conf, adversarial_pred = classify_with_art_model(adv_blur)
    
    attack_success = original_pred != adversarial_pred
    confidence_drop = conf - adversarial_conf
    
    # ë¡œê·¸ ì¶œë ¥
    print(f"ğŸ¨ ì›ë³¸: {original_class} ({conf:.3f})")
    print(f"ğŸ¯ ê³µê²©í›„: {adversarial_class} ({adversarial_conf:.3f})")
    print(f"ğŸ“Š ì„±ê³µ: {attack_success}, ì‹ ë¢°ë„ ë³€í™”: {confidence_drop:.3f}")

    return {
        'original_class': original_class,
        'adversarial_class': adversarial_class,
        'original_conf': conf,
        'adversarial_conf': adversarial_conf,
        'attack_success': attack_success,
        'confidence_drop': confidence_drop,
        'epsilon_used': eps,
        'sigma_used': sigma,
        'original_image': image_tensor.squeeze(0).detach(),
        'adversarial_image': adv_blur.squeeze(0).detach()
    }

def allowed_file(filename):
    ALLOWED_EXTENSIONS = {'png', 'jpg', 'jpeg', 'gif', 'bmp'}
    return '.' in filename and \
            filename.rsplit('.', 1)[1].lower() in ALLOWED_EXTENSIONS

def tensor_to_base64(tensor):
    img_np = tensor.permute(1, 2, 0).cpu().numpy()
    img_np = np.clip(img_np * 255, 0, 255).astype(np.uint8)
    img = Image.fromarray(img_np)
    
    buffer = io.BytesIO()
    img.save(buffer, format='PNG')
    img_str = base64.b64encode(buffer.getvalue()).decode()
    return f"data:image/png;base64,{img_str}"

@app.route('/')
def index():
    return render_template('index.html')

@app.route('/upload', methods=['POST'])
def upload_file():
    try:
        if 'file' not in request.files:
            return jsonify({'error': 'íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤'})
        
        file = request.files['file']
        if file.filename == '':
            return jsonify({'error': 'íŒŒì¼ì„ ì„ íƒí•´ì£¼ì„¸ìš”'})
        
        if not allowed_file(file.filename):
            return jsonify({'error': 'ì§€ì›í•˜ì§€ ì•ŠëŠ” íŒŒì¼ í˜•ì‹ì…ë‹ˆë‹¤'})
        
        # ì´ë¯¸ì§€ ì²˜ë¦¬
        img = Image.open(file.stream).convert('RGB')
        img_tensor = flexible_resize_transform(img)
        result = fgsm_attack_with_blur(img_tensor)
        
        return jsonify({
            'originalFilePath': tensor_to_base64(result['original_image']),
            'processedFilePath': tensor_to_base64(result['adversarial_image']),
            'epsilon': float(result.get('epsilon_used', 0.03)),
            
            # ì¶”ê°€ ì •ë³´
            'attackSuccess': result.get('attack_success', False),
            'originalPrediction': result.get('original_class', 'Unknown'),
            'adversarialPrediction': result.get('adversarial_class', 'Unknown'),
            'originalConfidence': f"{result.get('original_conf', 0):.3f}",
            'adversarialConfidence': f"{result.get('adversarial_conf', 0):.3f}",
            'confidenceDrop': f"{result.get('confidence_drop', 0)*100:.1f}%",
            'message': 'ì„¤ì • ì™„ë£Œ'
        })
        
    except Exception as e:
        return jsonify({'error': f'ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {str(e)}'})

@app.route('/test-art-model', methods=['GET'])
def test_art_model():
    """ì˜ˆìˆ  ë¶„ë¥˜ ëª¨ë¸ í…ŒìŠ¤íŠ¸"""
    try:
        if not art_model:
            return jsonify({
                'error': 'ì˜ˆìˆ  ë¶„ë¥˜ ëª¨ë¸ì´ ë¡œë“œë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤',
                'modelStatus': 'ì‹¤íŒ¨',
                'supportedClasses': 0
            })
        
        return jsonify({
            'modelStatus': 'ì •ìƒ',
            'modelName': 'WikiArt-Style (137 Classes)',
            'supportedClasses': len(art_model.config.id2label),
            'sampleClasses': list(art_model.config.id2label.values())[:15],
            'message': 'ğŸ¨ WikiArt-Style ì˜ˆìˆ  ë¶„ë¥˜ ëª¨ë¸ ì •ìƒ ë™ì‘'
        })
    except Exception as e:
        return jsonify({'error': f'ëª¨ë¸ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}'})


if __name__ == '__main__':
    app.run(debug=True, host='0.0.0.0', port=5002)
